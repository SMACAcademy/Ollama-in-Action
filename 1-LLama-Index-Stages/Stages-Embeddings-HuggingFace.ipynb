{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the embedding model\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an embedding for a single sentence\n",
    "single_embedding = embed_model.get_text_embedding(\"Embeddings represent text as numerical vectors in AI systems.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(single_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Single embedding length: {len(single_embedding)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the statements\n",
    "statements = [\n",
    "    \"The cat is on the mat.\",                     # Set 1 - Stmt 1\n",
    "    \"The sun rises in the east.\",                 # Unrelated - Stmt 2\n",
    "    \"The feline rests on the carpet.\",            # Set 1 - Stmt 3\n",
    "    \"Artificial Intelligence is fascinating.\",    # Set 2 - Stmt 4\n",
    "    \"Machine learning drives AI advancements.\",   # Set 2 - Stmt 5\n",
    "    \"Birds fly in the sky.\",                      # Unrelated - Stmt 6\n",
    "    \"Deep learning is a subset of AI.\",           # Set 2 - Stmt 7\n",
    "    \"Cat and Cow are domestic animals\",           # Set 1  - Stmt 8\n",
    "    \"Equity, mutual funds and stocks are various options to invest\", # Set 3 - Stmt 9\n",
    "    \"Gold can be used as hedge towards the investement\", # Set 3 - Stmt 10\n",
    "    \"Nifty and Sensex are major index in India\", # Set 3 - Stmt 11\n",
    "    \"Nasdaq, Dow and S&P 100 are major index in India\", # Set 3 - Stmt 12\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Generate embeddings\n",
    "embeddings = [embed_model.get_text_embedding(statement) for statement in statements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display information about the embeddings\n",
    "for i, emb in enumerate(embeddings):\n",
    "    print(f\"Embedding {i + 1}: Length = {len(emb)}, First 5 dimensions = {emb[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Calculate cosine similarity\n",
    "similarity_matrix = cosine_similarity(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Visualize the similarity matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(similarity_matrix, cmap='coolwarm', interpolation='nearest')\n",
    "plt.colorbar(label='Cosine Similarity')\n",
    "plt.xticks(range(len(statements)), [f\"Stmt {i+1}\" for i in range(len(statements))], rotation=45)\n",
    "plt.yticks(range(len(statements)), [f\"Stmt {i+1}\" for i in range(len(statements))])\n",
    "plt.title(\"Cosine Similarity Between Statements\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 6: Analyze relationships in 2D using PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "reduced_embeddings = pca.fit_transform(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scatter plot to visualize relationships\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, (x, y) in enumerate(reduced_embeddings):\n",
    "    plt.scatter(x, y, label=f\"Stmt {i+1}\")\n",
    "    plt.text(x + 0.02, y, f\"Stmt {i+1}\", fontsize=9)\n",
    "\n",
    "plt.title(\"Statement Relationships (PCA Reduced)\")\n",
    "plt.xlabel(\"PCA Dimension 1\")\n",
    "plt.ylabel(\"PCA Dimension 2\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
